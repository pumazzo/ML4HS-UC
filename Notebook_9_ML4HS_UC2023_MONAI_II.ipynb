{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pumazzo/ML4HS-UC/blob/main/Notebook_9_ML4HS_UC2023_MONAI_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88432a23",
      "metadata": {
        "id": "88432a23"
      },
      "source": [
        "# Spleen Segmentation example\n",
        "\n",
        "Now,we will implement Spleen segmentation using the Medical Decathalon dataset. We'll follow these general steps:  \n",
        "\n",
        "1. Transforms for dictionary format data.\n",
        "2. Load Nifti image with metadata.\n",
        "3. Add channel dim to the data if no channel dimension.\n",
        "4. Scale medical image intensity with expected range.\n",
        "5. Crop out a batch of balanced images based on positive / negative label ratio.\n",
        "6. Cache IO and transforms to accelerate training and validation.\n",
        "7. 3D UNet model, Dice loss function, Mean Dice metric for 3D segmentation task.\n",
        "8. Sliding window inference method.\n",
        "9. Deterministic training for reproducibility.\n",
        "\n",
        "This tutorial is derived from\n",
        "https://github.com/Project-MONAI/MONAIBootcamp2021/blob/main/day3/msd_spleen_segmentation-solution.ipynb\n",
        "\n",
        "\n",
        "Check here for other resources on transfer learning\n",
        "\n",
        "https://github.com/Project-MONAI/MONAI/discussions/3451\n",
        "\n",
        "\n",
        "###See the slides for an example\n",
        "[SLIDES](https://docs.google.com/presentation/d/1Duj8qf6L9gDZrY3qx_DmGrm85PzqBfdK97McbrlJ1ls/edit?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Turn On GPU runtime\n",
        "- go to runtime\n",
        "- change runtime type\n",
        "- select GPU"
      ],
      "metadata": {
        "id": "wayJkgWjpcmi"
      },
      "id": "wayJkgWjpcmi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abd2bcd8",
      "metadata": {
        "id": "abd2bcd8"
      },
      "outputs": [],
      "source": [
        "!python -c \"import monai\" || pip install -qU \"monai[ignite, nibabel, torchvision, tqdm]==0.8.1\"\n",
        "#!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel, lmdb, tqdm]\"\n",
        "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/Project-MONAI/MONAI.git\n",
        "! cd MONAI/\n",
        "! pip install -e '.[nibabel,skimage,ignite,torchvision,tqdm]'"
      ],
      "metadata": {
        "id": "SsehEWnDdBil",
        "outputId": "b5d96fc7-07a6-4339-cded-2e25a8227a3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "SsehEWnDdBil",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MONAI'...\n",
            "remote: Enumerating objects: 35770, done.\u001b[K\n",
            "remote: Counting objects: 100% (426/426), done.\u001b[K\n",
            "remote: Compressing objects: 100% (196/196), done.\u001b[K\n",
            "remote: Total 35770 (delta 270), reused 347 (delta 230), pack-reused 35344\u001b[K\n",
            "Receiving objects: 100% (35770/35770), 63.15 MiB | 11.01 MiB/s, done.\n",
            "Resolving deltas: 100% (28535/28535), done.\n",
            "Obtaining file:///content\n",
            "\u001b[31mERROR: file:///content does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2677df0a",
      "metadata": {
        "id": "2677df0a",
        "outputId": "b5c13f35-a0f7-49cd-ec49-5a9a35db74ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MONAI version: 0.8.1\n",
            "Numpy version: 1.23.5\n",
            "Pytorch version: 1.13.1+cu117\n",
            "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
            "MONAI rev id: 71ff399a3ea07aef667b23653620a290364095b1\n",
            "\n",
            "Optional dependencies:\n",
            "Pytorch Ignite version: 0.4.8\n",
            "Nibabel version: 4.0.2\n",
            "scikit-image version: 0.19.3\n",
            "Pillow version: 9.4.0\n",
            "Tensorboard version: 2.12.3\n",
            "gdown version: 4.6.6\n",
            "TorchVision version: 0.14.1+cu117\n",
            "tqdm version: 4.66.1\n",
            "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "psutil version: 5.9.5\n",
            "pandas version: 1.5.3\n",
            "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "\n",
            "For details about installing the optional dependencies, please visit:\n",
            "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "from monai.apps import download_and_extract\n",
        "from monai.config import print_config\n",
        "from monai.utils import set_determinism\n",
        "\n",
        "print_config()\n",
        "set_determinism(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the dataset\n",
        "Spleen CT data from decathon med"
      ],
      "metadata": {
        "id": "en8oIYxu4yFI"
      },
      "id": "en8oIYxu4yFI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f4b4fa8",
      "metadata": {
        "id": "9f4b4fa8"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "root_dir=\".\"\n",
        "resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task09_Spleen.tar\"\n",
        "md5 = \"410d4a301da4e5b2f6f86ec3ddba524e\"\n",
        "\n",
        "compressed_file = os.path.join(root_dir, \"Task09_Spleen.tar\")\n",
        "data_dir = os.path.join(root_dir, \"Task09_Spleen\")\n",
        "if not os.path.exists(data_dir):\n",
        "    download_and_extract(resource, compressed_file, root_dir, md5)\n",
        "\n",
        "train_images = sorted(\n",
        "    glob.glob(os.path.join(data_dir, \"imagesTr\", \"*.nii.gz\")))\n",
        "train_labels = sorted(\n",
        "    glob.glob(os.path.join(data_dir, \"labelsTr\", \"*.nii.gz\")))\n",
        "data_dicts = [\n",
        "    {\"image\": image_name, \"label\": label_name}\n",
        "    for image_name, label_name in zip(train_images, train_labels)\n",
        "]\n",
        "train_files, val_files = data_dicts[:-9], data_dicts[-9:]\n",
        "\n",
        "set_determinism(seed=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now we need to build a pipeline from datafiles to the examples (cubes) we want to feed to the network\n",
        "\n",
        "Validation and training have two different pipelines. Usually we don't want data augmentation in the training samples but the normalization pipeline has to be the same.\n",
        "\n",
        "As usual we want that the same cropping is applied to both the image and the segmentation"
      ],
      "metadata": {
        "id": "7RPsnUlp4_Wm"
      },
      "id": "7RPsnUlp4_Wm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a76acac",
      "metadata": {
        "id": "8a76acac"
      },
      "outputs": [],
      "source": [
        "from monai.transforms import (\n",
        "    Compose,\n",
        "    LoadImaged,\n",
        "    EnsureChannelFirstd,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    ScaleIntensityRanged,\n",
        "    CropForegroundd,\n",
        "    RandCropByPosNegLabeld,\n",
        "    EnsureTyped\n",
        ")\n",
        "#\n",
        "train_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),# load the image\n",
        "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),# channel first\n",
        "        Spacingd(keys=[\"image\", \"label\"], pixdim=(\n",
        "            1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),# resample the volume so all the CTs have the same RESOLUTION (spatial normalization) (the clara models want a specific resolution. Check it)\n",
        "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),# Turn the volume so thath the orientation (how the patient is put in the machine) is always the same\n",
        "        ScaleIntensityRanged(\n",
        "            keys=[\"image\"], a_min=-57, a_max=164,# CT intensity values has a physical meaning tied to the density of the tissues so we can decide which parts are important in our case\n",
        "            # usually air (and lungs) have a low density and thus low intensity (< -500)\n",
        "            # bones have a very high density (>500)\n",
        "            # splens like other internal organs have a density in the middle. After the intensity cut we normalize\n",
        "            b_min=0.0, b_max=1.0, clip=True,\n",
        "        ),\n",
        "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),# remove the background\n",
        "        RandCropByPosNegLabeld(# crop patches of a give size. The number of patches that contain the spleen or not is automatically balanced (pos/neg)\n",
        "            keys=[\"image\", \"label\"],\n",
        "            label_key=\"label\",\n",
        "            spatial_size=(96, 96, 96),\n",
        "            pos=1,\n",
        "            neg=1,\n",
        "            num_samples=4,\n",
        "            image_key=\"image\",\n",
        "            image_threshold=0,\n",
        "        ),\n",
        "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "    ]\n",
        ")\n",
        "val_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "        Spacingd(keys=[\"image\", \"label\"], pixdim=(\n",
        "            1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
        "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "        ScaleIntensityRanged(\n",
        "            keys=[\"image\"], a_min=-57, a_max=164,\n",
        "            b_min=0.0, b_max=1.0, clip=True,\n",
        "        ),\n",
        "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
        "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc3e8b10",
      "metadata": {
        "id": "bc3e8b10",
        "outputId": "3785d050-d33a-4752-f90d-ca1790633eea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dataset: 100%|██████████| 32/32 [02:28<00:00,  4.64s/it]\n",
            "Loading dataset: 100%|██████████| 9/9 [00:33<00:00,  3.71s/it]\n"
          ]
        }
      ],
      "source": [
        "from monai.data import CacheDataset, DataLoader\n",
        "\n",
        "train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=2)# We will cache (\"save in RAM\") the dataset to speed up the training\n",
        "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=2)\n",
        "\n",
        "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=1)\n",
        "val_loader = DataLoader(val_ds, batch_size=1, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir models\n",
        "! mkdir config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QztU39wyx6h-",
        "outputId": "b3b29478-19a7-4c29-8016-5541eff89f17"
      },
      "id": "QztU39wyx6h-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘models’: File exists\n",
            "mkdir: cannot create directory ‘config’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eccc4ee9",
      "metadata": {
        "id": "eccc4ee9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c1097a6-a199-487a-9c61-e5e84ce20a8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using a randomly init. model.\n"
          ]
        }
      ],
      "source": [
        "from monai.networks.nets import UNet\n",
        "from monai.networks.layers import Norm\n",
        "from monai.losses import DiceLoss\n",
        "from monai.metrics import DiceMetric\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "\n",
        "# we will initialize a model of the same capacity\n",
        "print(\"using a randomly init. model.\")\n",
        "model = UNet(\n",
        "  dimensions=3,\n",
        "  in_channels=1,\n",
        "  out_channels=2,\n",
        "  channels=(16, 32, 64, 128, 256),\n",
        "  strides=(2, 2, 2, 2),\n",
        "  num_res_units=2,\n",
        "  norm=Norm.BATCH,\n",
        ")\n",
        "\n",
        "model=model.to(device)\n",
        "loss_function = DiceLoss(to_onehot_y=True, softmax=True)# Dice loss (in this case is ready to use in MONAI)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), 3e-3)\n",
        "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93504727",
      "metadata": {
        "id": "93504727",
        "outputId": "003bd562-a229-481f-d777-dee29682adc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "epoch 1/35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/monai/transforms/post/array.py:177: UserWarning: `to_onehot=True/False` is deprecated, please use `to_onehot=num_classes` instead.\n",
            "  warnings.warn(\"`to_onehot=True/False` is deprecated, please use `to_onehot=num_classes` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/4, train_loss: 0.6819\n",
            "2/4, train_loss: 0.6614\n",
            "3/4, train_loss: 0.6341\n",
            "4/4, train_loss: 0.6198\n",
            "epoch 1 average loss: 0.6493\n",
            "----------\n",
            "epoch 2/35\n",
            "1/4, train_loss: 0.6035\n",
            "2/4, train_loss: 0.5975\n",
            "3/4, train_loss: 0.5713\n",
            "4/4, train_loss: 0.5724\n",
            "epoch 2 average loss: 0.5862\n",
            "----------\n",
            "epoch 3/35\n",
            "1/4, train_loss: 0.5735\n",
            "2/4, train_loss: 0.5663\n",
            "3/4, train_loss: 0.5389\n",
            "4/4, train_loss: 0.5661\n",
            "epoch 3 average loss: 0.5612\n",
            "----------\n",
            "epoch 4/35\n",
            "1/4, train_loss: 0.5394\n",
            "2/4, train_loss: 0.5317\n",
            "3/4, train_loss: 0.5345\n",
            "4/4, train_loss: 0.5344\n",
            "epoch 4 average loss: 0.5350\n",
            "----------\n",
            "epoch 5/35\n",
            "1/4, train_loss: 0.5181\n",
            "2/4, train_loss: 0.5177\n",
            "3/4, train_loss: 0.5121\n",
            "4/4, train_loss: 0.4899\n",
            "epoch 5 average loss: 0.5095\n",
            "saved new best metric model\n",
            "current epoch: 5 current mean dice: 0.0426\n",
            "best mean dice: 0.0426 at epoch: 5\n",
            "----------\n",
            "epoch 6/35\n",
            "1/4, train_loss: 0.5086\n",
            "2/4, train_loss: 0.5116\n",
            "3/4, train_loss: 0.4492\n",
            "4/4, train_loss: 0.4802\n",
            "epoch 6 average loss: 0.4874\n",
            "----------\n",
            "epoch 7/35\n",
            "1/4, train_loss: 0.4631\n",
            "2/4, train_loss: 0.4815\n",
            "3/4, train_loss: 0.4546\n",
            "4/4, train_loss: 0.4484\n",
            "epoch 7 average loss: 0.4619\n",
            "----------\n",
            "epoch 8/35\n",
            "1/4, train_loss: 0.4090\n",
            "2/4, train_loss: 0.4296\n",
            "3/4, train_loss: 0.4703\n",
            "4/4, train_loss: 0.4541\n",
            "epoch 8 average loss: 0.4407\n",
            "----------\n",
            "epoch 9/35\n",
            "1/4, train_loss: 0.4291\n",
            "2/4, train_loss: 0.4386\n",
            "3/4, train_loss: 0.4114\n",
            "4/4, train_loss: 0.3869\n",
            "epoch 9 average loss: 0.4165\n",
            "----------\n",
            "epoch 10/35\n",
            "1/4, train_loss: 0.4062\n",
            "2/4, train_loss: 0.3798\n",
            "3/4, train_loss: 0.3559\n",
            "4/4, train_loss: 0.3752\n",
            "epoch 10 average loss: 0.3793\n",
            "saved new best metric model\n",
            "current epoch: 10 current mean dice: 0.0814\n",
            "best mean dice: 0.0814 at epoch: 10\n",
            "----------\n",
            "epoch 11/35\n",
            "1/4, train_loss: 0.3976\n",
            "2/4, train_loss: 0.3910\n",
            "3/4, train_loss: 0.3307\n",
            "4/4, train_loss: 0.3835\n",
            "epoch 11 average loss: 0.3757\n",
            "----------\n",
            "epoch 12/35\n",
            "1/4, train_loss: 0.3411\n",
            "2/4, train_loss: 0.3793\n",
            "3/4, train_loss: 0.3130\n",
            "4/4, train_loss: 0.3497\n",
            "epoch 12 average loss: 0.3458\n",
            "----------\n",
            "epoch 13/35\n",
            "1/4, train_loss: 0.3401\n",
            "2/4, train_loss: 0.3548\n",
            "3/4, train_loss: 0.3050\n",
            "4/4, train_loss: 0.3865\n",
            "epoch 13 average loss: 0.3466\n",
            "----------\n",
            "epoch 14/35\n",
            "1/4, train_loss: 0.2833\n",
            "2/4, train_loss: 0.3597\n",
            "3/4, train_loss: 0.2871\n",
            "4/4, train_loss: 0.3182\n",
            "epoch 14 average loss: 0.3121\n",
            "----------\n",
            "epoch 15/35\n",
            "1/4, train_loss: 0.3132\n",
            "2/4, train_loss: 0.2316\n",
            "3/4, train_loss: 0.3243\n",
            "4/4, train_loss: 0.3304\n",
            "epoch 15 average loss: 0.2999\n",
            "saved new best metric model\n",
            "current epoch: 15 current mean dice: 0.2876\n",
            "best mean dice: 0.2876 at epoch: 15\n",
            "----------\n",
            "epoch 16/35\n",
            "1/4, train_loss: 0.2539\n",
            "2/4, train_loss: 0.3031\n",
            "3/4, train_loss: 0.2535\n",
            "4/4, train_loss: 0.2508\n",
            "epoch 16 average loss: 0.2653\n",
            "----------\n",
            "epoch 17/35\n",
            "1/4, train_loss: 0.2741\n",
            "2/4, train_loss: 0.3032\n",
            "3/4, train_loss: 0.2832\n",
            "4/4, train_loss: 0.2405\n",
            "epoch 17 average loss: 0.2752\n",
            "----------\n",
            "epoch 18/35\n",
            "1/4, train_loss: 0.2637\n",
            "2/4, train_loss: 0.2878\n",
            "3/4, train_loss: 0.2711\n",
            "4/4, train_loss: 0.2388\n",
            "epoch 18 average loss: 0.2653\n",
            "----------\n",
            "epoch 19/35\n",
            "1/4, train_loss: 0.1919\n",
            "2/4, train_loss: 0.2289\n",
            "3/4, train_loss: 0.2823\n",
            "4/4, train_loss: 0.2570\n",
            "epoch 19 average loss: 0.2400\n",
            "----------\n",
            "epoch 20/35\n",
            "1/4, train_loss: 0.2414\n",
            "2/4, train_loss: 0.2205\n",
            "3/4, train_loss: 0.2568\n",
            "4/4, train_loss: 0.2128\n",
            "epoch 20 average loss: 0.2328\n",
            "saved new best metric model\n",
            "current epoch: 20 current mean dice: 0.6245\n",
            "best mean dice: 0.6245 at epoch: 20\n",
            "----------\n",
            "epoch 21/35\n",
            "1/4, train_loss: 0.2401\n",
            "2/4, train_loss: 0.2956\n",
            "3/4, train_loss: 0.2691\n",
            "4/4, train_loss: 0.3308\n",
            "epoch 21 average loss: 0.2839\n",
            "----------\n",
            "epoch 22/35\n",
            "1/4, train_loss: 0.1978\n",
            "2/4, train_loss: 0.2946\n",
            "3/4, train_loss: 0.2641\n",
            "4/4, train_loss: 0.2111\n",
            "epoch 22 average loss: 0.2419\n",
            "----------\n",
            "epoch 23/35\n",
            "1/4, train_loss: 0.2800\n",
            "2/4, train_loss: 0.2334\n",
            "3/4, train_loss: 0.2030\n",
            "4/4, train_loss: 0.2564\n",
            "epoch 23 average loss: 0.2432\n",
            "----------\n",
            "epoch 24/35\n",
            "1/4, train_loss: 0.2268\n",
            "2/4, train_loss: 0.1911\n",
            "3/4, train_loss: 0.2710\n",
            "4/4, train_loss: 0.2245\n",
            "epoch 24 average loss: 0.2284\n",
            "----------\n",
            "epoch 25/35\n",
            "1/4, train_loss: 0.2413\n",
            "2/4, train_loss: 0.2322\n",
            "3/4, train_loss: 0.2114\n",
            "4/4, train_loss: 0.2569\n",
            "epoch 25 average loss: 0.2355\n",
            "saved new best metric model\n",
            "current epoch: 25 current mean dice: 0.7061\n",
            "best mean dice: 0.7061 at epoch: 25\n",
            "----------\n",
            "epoch 26/35\n",
            "1/4, train_loss: 0.2340\n",
            "2/4, train_loss: 0.1879\n",
            "3/4, train_loss: 0.2367\n",
            "4/4, train_loss: 0.2317\n",
            "epoch 26 average loss: 0.2225\n",
            "----------\n",
            "epoch 27/35\n",
            "1/4, train_loss: 0.2288\n",
            "2/4, train_loss: 0.2039\n",
            "3/4, train_loss: 0.2360\n",
            "4/4, train_loss: 0.2116\n",
            "epoch 27 average loss: 0.2201\n",
            "----------\n",
            "epoch 28/35\n",
            "1/4, train_loss: 0.2071\n",
            "2/4, train_loss: 0.2404\n",
            "3/4, train_loss: 0.1996\n",
            "4/4, train_loss: 0.2556\n",
            "epoch 28 average loss: 0.2257\n",
            "----------\n",
            "epoch 29/35\n",
            "1/4, train_loss: 0.2536\n",
            "2/4, train_loss: 0.2411\n",
            "3/4, train_loss: 0.2387\n",
            "4/4, train_loss: 0.2230\n",
            "epoch 29 average loss: 0.2391\n",
            "----------\n",
            "epoch 30/35\n",
            "1/4, train_loss: 0.2139\n",
            "2/4, train_loss: 0.1232\n",
            "3/4, train_loss: 0.2659\n",
            "4/4, train_loss: 0.1844\n",
            "epoch 30 average loss: 0.1969\n",
            "current epoch: 30 current mean dice: 0.6504\n",
            "best mean dice: 0.7061 at epoch: 25\n",
            "----------\n",
            "epoch 31/35\n",
            "1/4, train_loss: 0.2701\n",
            "2/4, train_loss: 0.2805\n",
            "3/4, train_loss: 0.2570\n",
            "4/4, train_loss: 0.2711\n",
            "epoch 31 average loss: 0.2697\n",
            "----------\n",
            "epoch 32/35\n",
            "1/4, train_loss: 0.3264\n",
            "2/4, train_loss: 0.2339\n",
            "3/4, train_loss: 0.2569\n",
            "4/4, train_loss: 0.1898\n",
            "epoch 32 average loss: 0.2517\n",
            "----------\n",
            "epoch 33/35\n",
            "1/4, train_loss: 0.3211\n",
            "2/4, train_loss: 0.2060\n",
            "3/4, train_loss: 0.1484\n",
            "4/4, train_loss: 0.2216\n",
            "epoch 33 average loss: 0.2243\n",
            "----------\n",
            "epoch 34/35\n",
            "1/4, train_loss: 0.2823\n",
            "2/4, train_loss: 0.1850\n"
          ]
        }
      ],
      "source": [
        "from monai.data.utils import decollate_batch\n",
        "from monai.transforms import EnsureType, AsDiscrete\n",
        "from monai.inferers import sliding_window_inference\n",
        "\n",
        "max_epochs = 35\n",
        "val_interval = 5\n",
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "epoch_loss_values = []\n",
        "metric_values = []\n",
        "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=True, n_classes=2)])# labels are transformed to one-hot encoded vectors\n",
        "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=True, n_classes=2)])\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    for batch_data in train_loader:\n",
        "        step += 1\n",
        "        inputs, labels = (\n",
        "            batch_data[\"image\"].to(device),\n",
        "            batch_data[\"label\"].to(device),\n",
        "        )\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        print(\n",
        "            f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
        "            f\"train_loss: {loss.item():.4f}\")\n",
        "    epoch_loss /= step\n",
        "    epoch_loss_values.append(epoch_loss)\n",
        "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for val_data in val_loader:\n",
        "                val_inputs, val_labels = (\n",
        "                    val_data[\"image\"].to(device),\n",
        "                    val_data[\"label\"].to(device),\n",
        "                )\n",
        "                roi_size = (160, 160, 160)\n",
        "                sw_batch_size = 4\n",
        "                val_outputs = sliding_window_inference(# inference is performed with sliding window. Instead of random cubes the whole image is cubed, processed and then the prediction is put together\n",
        "                    val_inputs, roi_size, sw_batch_size, model)\n",
        "                val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
        "                val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
        "                # compute metric for current iteration\n",
        "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
        "\n",
        "            # aggregate the final mean dice result\n",
        "            metric = dice_metric.aggregate().item()\n",
        "            # reset the status for next validation round\n",
        "            dice_metric.reset()\n",
        "\n",
        "            metric_values.append(metric)\n",
        "            if metric > best_metric:\n",
        "                best_metric = metric\n",
        "                best_metric_epoch = epoch + 1\n",
        "                torch.save(model.state_dict(), os.path.join(\n",
        "                    root_dir, \"best_metric_model.pth\"))\n",
        "                print(\"saved new best metric model\")\n",
        "            print(\n",
        "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
        "                f\"\\nbest mean dice: {best_metric:.4f} \"\n",
        "                f\"at epoch: {best_metric_epoch}\"\n",
        "            )\n",
        "\n",
        "print(\n",
        "    f\"train completed, best_metric: {best_metric:.4f} \"\n",
        "    f\"at epoch: {best_metric_epoch}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "072a6680",
      "metadata": {
        "id": "072a6680"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(\"train\", (12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Epoch Average Loss\")\n",
        "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
        "y = epoch_loss_values\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Val Mean Dice\")\n",
        "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
        "y = metric_values\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b6fbbd4",
      "metadata": {
        "id": "1b6fbbd4"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(\n",
        "    os.path.join(root_dir, \"best_metric_model.pth\")))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, val_data in enumerate(val_loader):\n",
        "        roi_size = (160, 160, 160)\n",
        "        sw_batch_size = 4\n",
        "        val_outputs = sliding_window_inference(\n",
        "            val_data[\"image\"].to(device), roi_size, sw_batch_size, model\n",
        "        )\n",
        "        # plot the slice [:, :, 80]\n",
        "        plt.figure(\"check\", (18, 6))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title(f\"image {i}\")\n",
        "        plt.imshow(val_data[\"image\"][0, 0, :, :, 80], cmap=\"gray\")\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title(f\"label {i}\")\n",
        "        plt.imshow(val_data[\"label\"][0, 0, :, :, 80])\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.title(f\"output {i}\")\n",
        "        plt.imshow(torch.argmax(\n",
        "            val_outputs, dim=1).detach().cpu()[0, :, :, 80])\n",
        "        plt.show()\n",
        "        if i == 2:\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now we can decide if we want a pretrained model to fine tune or we want initialize a new model with random weigths.\n",
        "\n",
        " To speed up the training we will download an already traned model and fine tune it to our pipeline (parameters used in the pretrained model are a bit different so we can observe a small gain in the loss function using the fine tuning)\n",
        "\n",
        " https://github.com/Project-MONAI/monai-bootcamp/blob/main/MONAICore/MONAI%20Bundle%20and%20MONAI%20Model%20Zoo.ipynb"
      ],
      "metadata": {
        "id": "VlsNRKBNhl4k"
      },
      "id": "VlsNRKBNhl4k"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# At home suggestions:\n",
        "- Try to load a model that is not used for spleen segmentation from https://catalog.ngc.nvidia.com/models\n",
        "\n",
        "- Check if a pretrained model on a similar task (prastate segmentation, for example) will converge faster on the spleen dataset than an untrained model of the same capacity\n",
        "- Add other transformation to the pipeline. For example try to implement the noise addiction and image deformation."
      ],
      "metadata": {
        "id": "9RnJs3CZ8Sc1"
      },
      "id": "9RnJs3CZ8Sc1"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NjSxxPI-akPp"
      },
      "id": "NjSxxPI-akPp",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}